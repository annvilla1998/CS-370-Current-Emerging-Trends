# CS-370-Current-Emerging-Trends

For this deep Q-learning pathfinding project, I was provided with foundational code including the TreasureMaze class for environment management, the GameExperience class for storing training data, utility functions for visualization and completion checking, and the basic neural network model architecture. My primary contribution was implementing the qtrain function, which serves as the core training algorithm that combines all these components into a functional deep Q-learning system. This implementation required understanding how to balance exploration and exploitation using epsilon-greedy strategy, manage the training loop with proper episode handling and memory storage, integrate neural network training with experience replay, and implement logic for determining when the agent has successfully learned to solve the maze consistently.

Computer scientists solve complex problems by designing algorithms, creating software systems, and developing new technologies that impact virtually every aspect of modern life, from GPS navigation and autonomous vehicles to warehouse robots and game AI. This project exemplifies the systematic approach computer scientists use, beginning with understanding problem requirements and existing code structure, then identifying key components needed for the solution including the training loop, exploration strategy, and learning algorithm. I implemented the solution incrementally, testing each component and debugging issues as they arose, breaking down the complex problem of teaching an agent to navigate into smaller, manageable pieces like episode management, experience storage, and neural network training. This methodical approach of decomposition, implementation, and iterative refinement is fundamental to computer science problem-solving.

As a computer scientist developing AI systems, I have significant ethical responsibilities to both end users and organizations that extend beyond technical implementation. For end users, I must ensure that algorithms are reliable, fair, and transparent in their decision-making processes, which in pathfinding contexts means ensuring systems don't exhibit biased behavior that could disadvantage certain users or lead them into unsafe situations. For organizations, I have responsibilities to write maintainable, well-documented code and to honestly communicate the limitations and potential risks of AI systems. Additionally, I must consider broader societal implications of AI technologies, ensuring that my work contributes positively to society while being mindful of potential negative consequences such as job displacement or privacy concerns, recognizing that even seemingly simple pathfinding algorithms can have far-reaching impacts when deployed at scale.
